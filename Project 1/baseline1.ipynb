{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train.csv\", usecols=[\"class\", \"viewCount\",\"likeCount\", \"dislikeCount\", \"commentCount\"]) \n",
    "test_data = pd.read_csv(\"test_1.csv\", usecols=[\"ID\",\"viewCount\",\"likeCount\", \"dislikeCount\", \"commentCount\"])\n",
    "\n",
    "Y_train = train_data[\"class\"]\n",
    "\n",
    "X_train = train_data.drop(\"class\", axis=1)\n",
    "X_test = test_data.drop(\"ID\", axis=1)\n",
    "\n",
    "X_train = X_train.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x)))\n",
    "X_test = X_test.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>viewCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>dislikeCount</th>\n",
       "      <th>commentCount</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10509398.0</td>\n",
       "      <td>945921.0</td>\n",
       "      <td>5614.0</td>\n",
       "      <td>58844</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4829.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>22</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015456.0</td>\n",
       "      <td>36679.0</td>\n",
       "      <td>492.0</td>\n",
       "      <td>3739</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64629.0</td>\n",
       "      <td>2111.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>151</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>206468.0</td>\n",
       "      <td>1335.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>470</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7100</th>\n",
       "      <td>6276674.0</td>\n",
       "      <td>290190.0</td>\n",
       "      <td>1514.0</td>\n",
       "      <td>20274</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7101</th>\n",
       "      <td>9628.0</td>\n",
       "      <td>599.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>128</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7102</th>\n",
       "      <td>2137632.0</td>\n",
       "      <td>19496.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>1869</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7103</th>\n",
       "      <td>663682.0</td>\n",
       "      <td>27151.0</td>\n",
       "      <td>729.0</td>\n",
       "      <td>2377</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7104</th>\n",
       "      <td>17976.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>174</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7105 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       viewCount  likeCount  dislikeCount  commentCount  class\n",
       "0     10509398.0   945921.0        5614.0         58844   True\n",
       "1         4829.0       57.0          81.0            22  False\n",
       "2      1015456.0    36679.0         492.0          3739   True\n",
       "3        64629.0     2111.0          24.0           151  False\n",
       "4       206468.0     1335.0          96.0           470  False\n",
       "...          ...        ...           ...           ...    ...\n",
       "7100   6276674.0   290190.0        1514.0         20274  False\n",
       "7101      9628.0      599.0          50.0           128   True\n",
       "7102   2137632.0    19496.0        1034.0          1869   True\n",
       "7103    663682.0    27151.0         729.0          2377  False\n",
       "7104     17976.0      204.0          24.0           174  False\n",
       "\n",
       "[7105 rows x 5 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asdf = pd.DataFrame(train_data)\n",
    "asdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SO now we've loaded the data as per the baseline function. We want to implement a decision tree because our classifier is essentially a binary classifier. For this we want to check a few things. First i want to check the head of the data struct see how it's formatted. \n",
    "We're then going to go ahead and check the value counts for class to make sure our data isn't biased.\n",
    "\n",
    "Note: For attempt 1 I'm going to be using the datapoints that have numerical values. If I want a higher accuracy I may experiment with using Sentiment Analysis on the worded portions such as userComments and turn those words into nUmBeRz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       viewCount  likeCount  dislikeCount  commentCount\n",
      "0     10509398.0   945921.0        5614.0         58844\n",
      "1         4829.0       57.0          81.0            22\n",
      "2      1015456.0    36679.0         492.0          3739\n",
      "3        64629.0     2111.0          24.0           151\n",
      "4       206468.0     1335.0          96.0           470\n",
      "...          ...        ...           ...           ...\n",
      "7100   6276674.0   290190.0        1514.0         20274\n",
      "7101      9628.0      599.0          50.0           128\n",
      "7102   2137632.0    19496.0        1034.0          1869\n",
      "7103    663682.0    27151.0         729.0          2377\n",
      "7104     17976.0      204.0          24.0           174\n",
      "\n",
      "[7105 rows x 4 columns]\n",
      "(7105, 4)\n",
      "(7105, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_test1 = train_data.loc[:,train_data.columns!='class']\n",
    "x_test2 = train_data.loc[:,train_data.columns=='class']\n",
    "print(x_test1)\n",
    "print(x_test1.shape)\n",
    "print(x_test2.shape)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "X_new = SelectKBest(chi2, k=2).fit_transform(x_test1,x_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelectKBest(k=2, score_func=<function chi2 at 0x7fe830658b80>)\n",
      "[ True  True False False]\n",
      "SelectKBest(k=2, score_func=<function chi2 at 0x7fe830658b80>)\n"
     ]
    }
   ],
   "source": [
    "X_new.shape\n",
    "X_new2 = SelectKBest(chi2, k=2)\n",
    "print(X_new2.fit(x_test1,x_test2))\n",
    "X_new2.get_params()\n",
    "print(X_new2.get_support())\n",
    "X_new2.transform(x_test1)\n",
    "\n",
    "print(X_new2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization was already performed above when we loaded the data. We can get started with classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.0\n"
     ]
    }
   ],
   "source": [
    "import graphviz\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn import tree\n",
    "from sklearn.datasets import load_wine\n",
    "from IPython.display import SVG\n",
    "from graphviz import Source\n",
    "from IPython.display import display\n",
    "\n",
    "final_dataset = pd.concat([X_train, Y_train], axis=1, sort=False)\n",
    "col_names = [\"viewCount\",\"likeCount\",\"dislikeCount\",\"commentCount\",\"class\"]\n",
    "\n",
    "X = final_dataset.loc[:,final_dataset.columns!='class']\n",
    "Y = final_dataset['class']\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X, Y)\n",
    "\n",
    "#tree.plot_tree(model) \n",
    "#graph = Source(tree.export_graphviz(model , out_file=None , feature_names=col_names[:-1] , filled = True))\n",
    "\n",
    "#display(SVG(graph.pipe(format='svg')))\n",
    "\n",
    "Y_predicted = model.predict(X)\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy=accuracy_score(Y, Y_predicted)\n",
    "print('Accuracy on training set: '+str(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predicted\n",
    "\n",
    "Y_predicted2 = model.predict(X_test)\n",
    "\n",
    "xarray = np.asarray(test_data[\"ID\"])\n",
    "yarray = np.asarray(Y_predicted2)\n",
    "#xarray = np.array([0,1,2,3,4,5])\n",
    "#yarray = np.array([0,10,20,30,40,50])\n",
    "#here is your data, in two numpy arrays\n",
    "\n",
    "df = pd.DataFrame({\"ID\": xarray,\"class\":yarray})\n",
    "\n",
    "df.head(10)\n",
    "df.to_csv(\"submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Trying adaboost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "clf = AdaBoostClassifier(n_estimators=100, base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1e-3, random_state=0)\n",
    "\n",
    "model.fit(X,Y)\n",
    "\n",
    "Y_predicted = model.predict(X)\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy=accuracy_score(Y, Y_predicted)\n",
    "print('Accuracy on training set: '+str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predicted\n",
    "\n",
    "Y_predicted3 = model.predict(X_test)\n",
    "\n",
    "xarray = np.asarray(test_data[\"ID\"])\n",
    "yarray = np.asarray(Y_predicted3)\n",
    "#xarray = np.array([0,1,2,3,4,5])\n",
    "#yarray = np.array([0,10,20,30,40,50])\n",
    "#here is your data, in two numpy arrays\n",
    "\n",
    "df = pd.DataFrame({\"ID\": xarray,\"class\":yarray})\n",
    "\n",
    "df.head(10)\n",
    "df.to_csv(\"submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_predicted2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f122b2a9cddc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_predicted3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_predicted2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Y_predicted2' is not defined"
     ]
    }
   ],
   "source": [
    "np.array_equal(Y_predicted3, Y_predicted2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
