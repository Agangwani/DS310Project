{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import date, time, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_users = pd.read_csv(\"proj3_data/train_users.csv\")\n",
    "test_users = pd.read_csv(\"proj3_data/test_users.csv\")\n",
    "sessions = pd.read_csv(\"proj3_data/sessions.csv\")\n",
    "languages = pd.read_csv(\"proj3_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = train_users['country_destination']\n",
    "train_users.drop('country_destination', axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values_table(df):\n",
    "        # Total missing values\n",
    "        mis_val = df.isnull().sum()\n",
    "        \n",
    "        # Percentage of missing values\n",
    "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "        \n",
    "        # Make a table with the results\n",
    "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        \n",
    "        # Rename the columns\n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "        \n",
    "        # Sort the table by percentage of missing descending\n",
    "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(1)\n",
    "        \n",
    "        # Print some summary information\n",
    "        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n",
    "            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "              \" columns that have missing values.\")\n",
    "        \n",
    "        # Return the dataframe with missing information\n",
    "        return mis_val_table_ren_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_users.drop(['country_destination'], axis = 1)\n",
    "#Concatenating train and test data for EDA\n",
    "df_all = pd.concat((train_users, test_users), axis = 0, ignore_index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_list = []\n",
    "year_list = []\n",
    "month_list = []\n",
    "\n",
    "for i in df_all[\"date_account_created\"]:\n",
    "    date_time_obj = datetime.strptime(i, '%Y-%m-%d')\n",
    "    year = date_time_obj.date().year\n",
    "    month = date_time_obj.date().month\n",
    "    dates_list.append(date_time_obj)\n",
    "    year_list.append(year)\n",
    "    month_list.append(month)\n",
    "\n",
    "df_all[\"datetime_account_created\"] = dates_list\n",
    "df_all[\"year_account_created\"] = year_list\n",
    "df_all[\"month_account_created\"] = month_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_list = []\n",
    "year_list = []\n",
    "month_list = []\n",
    "\n",
    "for i in df_all[\"timestamp_first_active\"]:\n",
    "    time_stamp_obj = pd.to_datetime(i , format='%Y%m%d%H%M%S')\n",
    "    year = time_stamp_obj.date().year\n",
    "    month = time_stamp_obj.date().month\n",
    "    dates_list.append(time_stamp_obj)\n",
    "    year_list.append(year)\n",
    "    month_list.append(month)\n",
    "    \n",
    "df_all[\"datetime_first_active\"] = dates_list\n",
    "df_all[\"year_first_active\"] = year_list\n",
    "df_all[\"month_first_active\"] = month_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[\"created_after_active\"] = df_all[\"datetime_account_created\"] - df_all[\"datetime_first_active\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['age'].quantile(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['age'] = np.where(df_all['age'] > 110, 34, df_all['age'])\n",
    "df_all['age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_signup_device = df_all.groupby(['signup_method', 'first_device_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_median(series):\n",
    "    return series.fillna(series.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.age = by_signup_device['age'].transform(impute_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['first_affiliate_tracked'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracked = []\n",
    "\n",
    "for i in df_all['first_affiliate_tracked']:\n",
    "    if i == \"untracked\" or i == \"\":\n",
    "        isTracked = 0\n",
    "    else:\n",
    "        isTracked = 1\n",
    "    tracked.append(isTracked)\n",
    "\n",
    "df_all['is_first_affiliate_tracked'] = tracked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['created_after_active'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_all = df_all.rename(columns={\"id\":\"user_id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions.user_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seconds = sessions.groupby('user_id', as_index=False).agg({\"secs_elapsed\": \"sum\"})\n",
    "seconds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.merge(df_all, seconds, on=\"user_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['secs_elapsed'] = df_all['secs_elapsed'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_all['datetime_account_created'].dayofweek()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['is_first_affiliate_tracked'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.gender.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_all.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['day_account_created'] = df_all['datetime_account_created'].dt.day_name()\n",
    "df_all['day_first_active'] = df_all['datetime_first_active'].dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_acct_created = pd.get_dummies(df_all['day_account_created'])\n",
    "day_first_active = pd.get_dummies(df_all['day_first_active'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_acct_created = day_acct_created.rename(columns={\"Monday\": \"acct_created_Mon\", \"Tuesday\": \"acct_created_Tues\", \"Wednesday\": \"acct_created_Wed\",\n",
    "                                \"Thursday\": \"acct_created_Thurs\", \"Friday\": \"acct_created_Fri\", \"Saturday\": \"acct_created_Sat\", \n",
    "                                 \"Sunday\": \"acct_created_Sun\"})\n",
    "day_first_active = day_first_active.rename(columns={\"Monday\": \"first_active_Mon\", \"Tuesday\": \"first_active_Tues\", \"Wednesday\": \"first_active_Wed\",\n",
    "                                \"Thursday\": \"first_active_Thurs\", \"Friday\": \"first_active_Fri\", \"Saturday\": \"first_active_Sat\", \n",
    "                                 \"Sunday\": \"first_active_Sun\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_all.reset_index(drop=True),day_acct_created.reset_index(drop=True)], axis=1)\n",
    "df_all = pd.concat([df_all.reset_index(drop=True),day_first_active.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = pd.get_dummies(df_all[[\"signup_method\"]])\n",
    "affch = pd.get_dummies(df_all[[\"affiliate_channel\"]])\n",
    "affprov = pd.get_dummies(df_all[[\"affiliate_provider\"]])\n",
    "firstdevice = pd.get_dummies(df_all[[\"first_device_type\"]])\n",
    "browser = pd.get_dummies(df_all[[\"first_browser\"]])\n",
    "signup = pd.get_dummies(df_all[[\"signup_app\"]])\n",
    "genderdum = pd.get_dummies(df_all[[\"gender\"]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.concat([df2.reset_index(drop=True),method.reset_index(drop=True)], axis=1)\n",
    "df2 = pd.concat([df2.reset_index(drop=True),affch.reset_index(drop=True)], axis=1)\n",
    "df2 = pd.concat([df2.reset_index(drop=True),affprov.reset_index(drop=True)], axis=1)\n",
    "df2 = pd.concat([df2.reset_index(drop=True),firstdevice.reset_index(drop=True)], axis=1)\n",
    "df2 = pd.concat([df2.reset_index(drop=True),browser.reset_index(drop=True)], axis=1)\n",
    "df2 = pd.concat([df2.reset_index(drop=True),genderdum.reset_index(drop=True)], axis=1)\n",
    "df2 = pd.concat([df2.reset_index(drop=True),signup.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_table(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df2.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns_to_drop = ['user_id', 'date_account_created', 'timestamp_first_active', 'date_first_booking',\n",
    "#'gender', 'signup_method', 'signup_flow',affiliate_channel, affiliate_provider, \n",
    "#first_device_type, first_browser, signup_app\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df2.iloc[0:len(train),:]\n",
    "test = df2.iloc[len(train):,:]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
